import os
import json
import subprocess
from pydub import AudioSegment
import streamlit as st

# ---------------- ffmpeg æ£€æŸ¥ ----------------
def check_ffmpeg():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return True
    except Exception:
        return False

# ---------------- éŸ³é¢‘å¤„ç†å‡½æ•° ----------------
def load_segments_from_folder(folder_path, min_duration_sec=0.0):
    """
    ä»æŒ‡å®šç›®å½•åŠ è½½æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µä¿¡æ¯
    æ”¯æŒ .wavã€.flacã€.mp3
    .txt å†…å®¹ä¸º JSON æ ¼å¼: {"start": float, "end": float, "speaker": str}
    å¯é€šè¿‡ min_duration_sec å¿½ç•¥è¿‡çŸ­ç‰‡æ®µ
    """
    segments = []
    for fname in os.listdir(folder_path):
        if fname.endswith((".wav", ".flac", ".mp3")):
            base = os.path.splitext(fname)[0]
            audio_path = os.path.join(folder_path, fname)
            txt_path = os.path.join(folder_path, base + ".txt")
            if os.path.exists(txt_path):
                with open(txt_path, "r", encoding="utf-8") as f:
                    info = json.load(f)
                start = info.get("start", 0)
                end = info.get("end", 0)
                if end - start >= min_duration_sec:  # å¿½ç•¥è¿‡çŸ­ç‰‡æ®µ
                    segments.append({
                        "id": base,
                        "audio": audio_path,
                        "start": start,
                        "end": end,
                        "speaker": info.get("speaker", "")
                    })
    segments.sort(key=lambda x: int(x["id"]))  # æŒ‰æ•°å­—æ–‡ä»¶åæ’åº
    return segments

def merge_continuous_segments(segments, gap_threshold):
    """
    åˆå¹¶è¿ç»­ç‰‡æ®µï¼š
    - ç›¸é‚»æ–‡ä»¶åå¿…é¡»è¿ç»­æ•°å­—
    - start - prev.end <= gap_threshold
    """
    merged = []
    if not segments:
        return merged

    current_group = [segments[0]]
    for i in range(1, len(segments)):
        prev = segments[i - 1]
        curr = segments[i]
        prev_id = int(prev["id"])
        curr_id = int(curr["id"])
        if curr_id == prev_id + 1 and (curr["start"] - prev["end"] <= gap_threshold):
            current_group.append(curr)
        else:
            merged.append(current_group)
            current_group = [curr]
    merged.append(current_group)
    return merged

def combine_audio_segments(segment_group):
    """å°†ä¸€ä¸ª segment_group æ‹¼æ¥ä¸ºä¸€æ¡éŸ³é¢‘ï¼ˆè‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼‰"""
    combined = AudioSegment.empty()
    for seg in segment_group:
        path = seg["audio"]
        try:
            combined += AudioSegment.from_file(path)
        except Exception as e:
            st.error(f"âŒ æ— æ³•è§£ç æ–‡ä»¶ {path} ï¼š{e}")
    return combined

# ---------------- Streamlit UI ----------------
st.set_page_config(page_title="è¿ç»­è¯­éŸ³æ‹¼æ¥å·¥å…·", layout="wide")
st.title("ğŸ§ è¿ç»­è¯­éŸ³æ‹¼æ¥å·¥å…·")

if not check_ffmpeg():
    st.error("âŒ æœªæ£€æµ‹åˆ° ffmpegï¼Œè¯·å…ˆå®‰è£… ffmpeg å¹¶ç¡®ä¿å¯æ‰§è¡Œæ–‡ä»¶åœ¨ PATH ä¸­")
    st.stop()

# è¾“å…¥å‚æ•°
path = st.text_input("è¯·è¾“å…¥è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼š", value="")
output_dir = st.text_input("è¯·è¾“å…¥è¾“å‡ºç›®å½•è·¯å¾„ï¼š", value=os.path.join(path, "merged_results"))
gap_sec = st.number_input("æœ€å¤§å…è®¸é—´éš”ï¼ˆç§’ï¼‰", value=2.0, min_value=0.0, step=0.5)
min_duration_sec = st.number_input("å¿½ç•¥è¿‡çŸ­ç‰‡æ®µï¼ˆç§’ï¼Œå°äºæ­¤å€¼å°†è·³è¿‡ï¼‰", value=0.5, min_value=0.0, step=0.1)

if st.button("å¼€å§‹å¤„ç†") and path:
    if not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)

    # è·å–å­æ–‡ä»¶å¤¹
    folders = [os.path.join(path, f) for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]
    if not folders:
        st.warning("æœªæ£€æµ‹åˆ°å­æ–‡ä»¶å¤¹ï¼Œè¯·ç¡®è®¤è·¯å¾„æ­£ç¡®ã€‚")
    else:
        st.write(f"æ‰¾åˆ° {len(folders)} ä¸ªå­æ–‡ä»¶å¤¹")
        st.write(f"è¾“å‡ºç›®å½•ï¼š{output_dir}")

        # å¤„ç†æ¯ä¸ªå­æ–‡ä»¶å¤¹
        for folder in folders:
            st.subheader(f"ğŸ“ å¤„ç†å­ç›®å½•ï¼š{os.path.basename(folder)}")
            segments = load_segments_from_folder(folder, min_duration_sec=min_duration_sec)
            merged_groups = merge_continuous_segments(segments, gap_sec)
            st.write(f"å…± {len(merged_groups)} ç»„è¿ç»­ç‰‡æ®µ")

            for i, group in enumerate(merged_groups, start=1):
                combined_audio = combine_audio_segments(group)
                output_file = os.path.join(output_dir, f"{os.path.basename(folder)}_group{i}.wav")
                combined_audio.export(output_file, format="wav")
                st.audio(output_file)
                st.write(f"âœ… å¯¼å‡º: {output_file}")

        st.success("æ‰€æœ‰æ–‡ä»¶å¤¹å¤„ç†å®Œæˆ âœ…")